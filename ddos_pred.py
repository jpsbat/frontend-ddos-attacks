# -*- coding: utf-8 -*-
"""DDOS_Pred.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12ms-Ubq6tRnMX-7k3oFKF2jdlJ7Y7WqY

<font size="8"><center><b>Centro Universit√°rio Facens</b></center></font>

<font size="5"><center><b>Trabalho de Conclus√£o de Curso</b></center></font>

<font size="4"><center><b>Detec√ß√£o Inteligente De Ataques DDOS Utilizando Machine Learning</b></center></font>
  
<font size="3"><center>Prof. Orientadora Andr√©ia Leles</center></font>

# **Importando Bibliotecas**
"""

import os
from readline import redisplay
from tqdm import tqdm # type: ignore
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.ensemble import RandomForestClassifier

#!pip install scikeras[tensorflow]

from tensorflow.keras.models import Sequential # type: ignore
from tensorflow.keras.layers import Dense # type: ignore
from tensorflow.keras.optimizers import Adam # type: ignore
from tensorflow.keras.utils import to_categorical # type: ignore
#from scikeras.wrappers import KerasClassifier

import warnings
warnings.filterwarnings('ignore')

"""# **Leitura dos Dados**"""

from google.colab import files # type: ignore
files.upload()

os.makedirs(os.path.expanduser("~/.kaggle"), exist_ok=True)
import shutil
shutil.copy("kaggle.json", os.path.expanduser("~/.kaggle/"))
import stat
os.chmod(os.path.expanduser("~/.kaggle/kaggle.json"), stat.S_IRUSR | stat.S_IWUSR)

from kaggle.api.kaggle_api_extended import KaggleApi # type: ignore

api = KaggleApi()
api.authenticate()
api.dataset_download_files('dhoogla/cicddos2019', path='.', unzip=True)

import subprocess
subprocess.run(["unzip", "cicddos2019.zip", "-d", "cicddos2019"], check=True)

import os
from kaggle.api.kaggle_api_extended import KaggleApi # type: ignore

# Inicializar a API do Kaggle
api = KaggleApi()
api.authenticate()

# Baixar e extrair os arquivos
dataset = 'dhoogla/cicddos2019'
destino = 'dados_cicddos'
api.dataset_download_files(dataset, path=destino, unzip=True)

# Lista de arquivos desejados
arquivos_desejados = {
    'DNS-testing.parquet',
    'NTP-testing.parquet',
    'Syn-testing.parquet',
    'Syn-training.parquet',
    'UDP-testing.parquet',
    'UDP-training.parquet',
    'UDPLag-testing.parquet',
    'UDPLag-training.parquet',
}

# Coletar caminhos de treino e teste
caminhos_treino = []
caminhos_teste = []

for pasta, _, arquivos in os.walk(destino):
    for nome_arquivo in arquivos:
        if nome_arquivo in arquivos_desejados:
            caminho = os.path.join(pasta, nome_arquivo)
            if 'training' in nome_arquivo:
                caminhos_treino.append(caminho)
                print(f"Treino: {caminho}")
            elif 'testing' in nome_arquivo:
                caminhos_teste.append(caminho)
                print(f"Teste: {caminho}")

"""# **Processamento dos Dados**"""

# Identificar prefixos comuns entre arquivos de treino e teste
prefixos_treino = [c.split('/')[-1].split('-')[0] for c in caminhos_treino]
prefixos_teste = [c.split('/')[-1].split('-')[0] for c in caminhos_teste]
prefixos_comuns = list(set(prefixos_treino).intersection(prefixos_teste))

# Filtrar arquivos apenas com prefixos comuns
caminhos_treino = [c for c in caminhos_treino if c.split('/')[-1].split('-')[0] in prefixos_comuns]
caminhos_teste = [c for c in caminhos_teste if c.split('/')[-1].split('-')[0] in prefixos_comuns]

# Carregar os dados
df_treino = pd.concat([pd.read_parquet(c) for c in caminhos_treino], ignore_index=True)
df_teste = pd.concat([pd.read_parquet(c) for c in caminhos_teste], ignore_index=True)

print(df_treino.shape, df_teste.shape)

# Remover classe WebDDoS dos dados de teste
df_teste = df_teste[df_teste["Label"] != "WebDDoS"]

# Fun√ß√£o para identificar tipos de colunas
def obter_colunas(dataframe, lim_cat=10, lim_card=20):
    col_cat = [col for col in dataframe.columns if dataframe[col].dtypes == "O"]
    num_comportando_cat = [col for col in dataframe.columns if dataframe[col].nunique() < lim_cat and dataframe[col].dtypes != "O"]
    cat_alta_card = [col for col in dataframe.columns if dataframe[col].nunique() > lim_card and dataframe[col].dtypes == "O"]

    col_cat = col_cat + num_comportando_cat
    col_cat = [col for col in col_cat if col not in cat_alta_card]

    col_num = [col for col in dataframe.columns if dataframe[col].dtypes != "O"]
    col_num = [col for col in col_num if col not in num_comportando_cat]

    print(f"Total de observa√ß√µes: {dataframe.shape[0]}")
    print(f"Total de vari√°veis: {dataframe.shape[1]}")
    print(f"Colunas categ√≥ricas: {len(col_cat)}")
    print(f"Colunas num√©ricas: {len(col_num)}")
    print(f"Colunas categ√≥ricas com alta cardinalidade: {len(cat_alta_card)}")
    print(f"Colunas num√©ricas mas com comportamento categ√≥rico: {len(num_comportando_cat)}")
    print("\n")

    return col_cat, col_num, cat_alta_card

col_cat, col_num, cat_alta_card = obter_colunas(df_treino)

print(f"Colunas Categ√≥ricas: {col_cat}")
print(f"Colunas Num√©ricas: {col_num}")
print(f"Alta Cardinalidade: {cat_alta_card}")

"""# **Remo√ß√£o e Normaliza√ß√£o dos Dados**"""

# Verificar valores ausentes e duplicados
print(f"Total de valores ausentes: {df_treino.isnull().sum().sum()}")
print(f"Total de linhas duplicadas: {df_treino.duplicated().sum()}")

# Remover duplicadas
df_treino = df_treino.drop_duplicates()

# Remover colunas com valor √∫nico
col_valor_unico = [col for col in df_treino.columns if df_treino[col].nunique() == 1]
df_treino.drop(col_valor_unico, axis=1, inplace=True)
df_teste.drop(col_valor_unico, axis=1, inplace=True)

print(df_treino.shape, df_teste.shape)

# Remover colunas altamente correlacionadas
df_numerico = df_treino.select_dtypes(include=[np.number])
matriz_corr = df_numerico.corr().abs()
mascara = np.triu(np.ones(matriz_corr.shape), k=1).astype(bool)
tri_superior = matriz_corr.where(mascara)
col_corr_alta = [col for col in tri_superior.columns if any(tri_superior[col] > 0.8)]

print(f"Total de colunas altamente correlacionadas: {len(col_corr_alta)}")
print("Colunas altamente correlacionadas:", col_corr_alta)

df_treino.drop(col_corr_alta, axis=1, inplace=True)
df_teste.drop(col_corr_alta, axis=1, inplace=True)

print(df_treino.shape, df_teste.shape)

# Separar vari√°veis independentes e alvo
X_treino, X_valid, y_treino, y_valid = train_test_split(df_treino.drop("Label", axis=1), df_treino["Label"], test_size=0.2, random_state=42)
X_teste, y_teste = df_teste.drop("Label", axis=1), df_teste["Label"]

# Normalizar vari√°veis de entrada
escalador = MinMaxScaler()
X_treino = escalador.fit_transform(X_treino)
X_valid = escalador.transform(X_valid)
X_teste = escalador.transform(X_teste)

"""# **Matriz de Correla√ß√£o**"""

# Gr√°fico de Matriz de Correla√ß√£o para Colunas Num√©ricas
def matriz_correlacao(dataframe, tamanho_figura):
    if tamanho_figura:
        plt.figure(figsize=tamanho_figura)
    sns.heatmap(
        dataframe.corr(),
        annot=True,
        fmt=".1f",
        cmap="Greens",
        annot_kws={"size": 12}
    )
    plt.title("Matriz de Correla√ß√£o")
    plt.show()

# Exibir a matriz de correla√ß√£o para as vari√°veis num√©ricas
colunas_numericas = df_treino.select_dtypes(include=[np.number])
qtd_colunas_numericas = len(colunas_numericas.columns)
tamanho_figura = (qtd_colunas_numericas + 1, qtd_colunas_numericas + 1)

# Chamada da fun√ß√£o
matriz_correlacao(colunas_numericas, tamanho_figura)

"""# **Treinamento do Modelo**"""

# # Treinamento e avalia√ß√£o de modelo
# def treinar_modelo(X_treino, X_teste, y_treino, y_teste):
#     classificadores = {
#         "Random Forest": RandomForestClassifier(),
#     }

#     lista_metricas = []

#     for nome, modelo in tqdm(classificadores.items(), desc="Treinando modelos"):
#         print(f"Treinando {nome}...")

#         modelo.fit(X_treino, y_treino)
#         y_pred = modelo.predict(X_teste)

#         acuracia = accuracy_score(y_teste, y_pred)
#         precisao = precision_score(y_teste, y_pred, average='weighted', zero_division=0)
#         recall = recall_score(y_teste, y_pred, average='weighted', zero_division=0)
#         f1 = f1_score(y_teste, y_pred, average='weighted', zero_division=0)
#         cv_score = np.mean(cross_val_score(modelo, X_treino, y_treino, cv=5))

#         lista_metricas.append({
#             "Modelo": nome,
#             "Acur√°cia": acuracia,
#             "Precis√£o": precisao,
#             "Recall": recall,
#             "F1": f1,
#             "Valida√ß√£o Cruzada": cv_score
#         })

#     return pd.DataFrame(lista_metricas)

# # Rodar o treinamento
# resultados = treinar_modelo(X_treino, X_valid, y_treino, y_valid)
# display(resultados.style.background_gradient(cmap='viridis'))

def treinar_modelo(X_treino, X_teste, y_treino, y_teste):
    classificadores = {
        "Random Forest": RandomForestClassifier(),
        "Rede Neural": "KerasModel"
    }

    lista_metricas = []

    for nome, modelo in tqdm(classificadores.items(), desc="Treinando modelos"):
        print(f"\nTreinando {nome}...")

        if nome == "Rede Neural":
            # Garantir que X seja float32 (Keras exige isso)
            X_treino = X_treino.astype('float32')
            X_teste = X_teste.astype('float32')

            # Converter y para inteiro se necess√°rio
            if y_treino.dtype == 'object' or y_treino.dtype.name == 'category':
                le = LabelEncoder()
                y_treino = le.fit_transform(y_treino)
                y_teste = le.transform(y_teste)

            # Definir sa√≠da e fun√ß√£o de perda
            if np.unique(y_treino).shape[0] == 2:
                ativacao_saida = 'sigmoid'
                loss = 'binary_crossentropy'
                unidades_saida = 1
            else:
                ativacao_saida = 'softmax'
                loss = 'sparse_categorical_crossentropy'
                unidades_saida = np.unique(y_treino).shape[0]

            # Definir e treinar o modelo
            model = Sequential()
            model.add(Dense(64, input_dim=X_treino.shape[1], activation='relu'))
            model.add(Dense(32, activation='relu'))
            model.add(Dense(unidades_saida, activation=ativacao_saida))
            model.compile(optimizer=Adam(0.001), loss=loss, metrics=['accuracy'])

            model.fit(X_treino, y_treino, epochs=20, batch_size=32, verbose=0, validation_split=0.1)
            _, acuracia = model.evaluate(X_teste, y_teste, verbose=0)
            y_pred_prob = model.predict(X_teste)

            # Converter probabilidades para classes
            if unidades_saida == 1:
                y_pred = (y_pred_prob > 0.5).astype(int)
            else:
                y_pred = np.argmax(y_pred_prob, axis=1)

            modelo = model
            cv_score = np.nan  # n√£o aplic√°vel
        else:
            modelo.fit(X_treino, y_treino)
            y_pred = modelo.predict(X_teste)
            cv_score = np.mean(cross_val_score(modelo, X_treino, y_treino, cv=5))

        acuracia = accuracy_score(y_teste, y_pred)
        precisao = precision_score(y_teste, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_teste, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_teste, y_pred, average='weighted', zero_division=0)

        lista_metricas.append({
            "Modelo": nome,
            "Acur√°cia": acuracia,
            "Precis√£o": precisao,
            "Recall": recall,
            "F1": f1,
            "Valida√ß√£o Cruzada": cv_score
        })

    return pd.DataFrame(lista_metricas)

# Rodar o treinamento
resultados = treinar_modelo(X_treino, X_valid, y_treino, y_valid)
redisplay(resultados.style.background_gradient(cmap='viridis'))

"""# **M√©tricas e Resultados**"""

# Extrair as m√©tricas
acuracia_final = resultados["Acur√°cia"].iloc[0]
precisao_final = resultados["Precis√£o"].iloc[0]
revocacao_final = resultados["Recall"].iloc[0]
f1_final = resultados["F1"].iloc[0]
cv_final = resultados["Valida√ß√£o Cruzada"].iloc[0]

# Criar uma m√©dia das m√©tricas principais
media_metricas = np.mean([acuracia_final, precisao_final, revocacao_final, f1_final, cv_final])

print(media_metricas)

# L√≥gica de decis√£o baseada nessa m√©dia geral
if 0.90 <= media_metricas <= 1:
    print("üî¥ Ataque detectado")
elif 0.60 <= media_metricas < 0.90:
    print("üü† Movimenta√ß√£o suspeita detectada")
elif 0.0 <= media_metricas < 0.60:
    print("üü¢ Ambiente aparentemente normal")
else:
    print("‚ö†Ô∏è Valor de m√©tricas fora do esperado")